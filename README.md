<h1 align="center"><img src="https://cdn-avatars.huggingface.co/v1/production/uploads/63839e9962badff4326cf360/k4Q7R4XLDMp_1VF4C6GEd.jpeg" width="25"> M-A-P Daily Paper</h1>
<p align="center">
<a href="https://github.com/DenverCoder1/readme-typing-svg"><img src="https://media.giphy.com/media/Rn26lWjqA0uUU/giphy.gif" width="100"></a>
</p>
<hr/>
<h4 align="center">The <a href=https://m-a-p.ai>M-A-P</a> daily paper project curates and reviews a selection of new papers published daily on arXiv, providing insightful commentary on cutting-edge research across various scientific disciplines.</h4>
<br>

[Click to view previous selection](https://m-a-p.ai/DailyPaper/archived_papers.html).

<hr/>

## üî• Paper Today: 15/10/2024

<table class="center">
| Paper | Affiliation | Comments |
|:-------------|:-------------|:-------------|
| **TMGBench: A Systematic Game Benchmark for Evaluating Strategic Reasoning Abilities of LLMs** | HKU, Harbin Institute of Technology | TMGBench includes 144 types of games based on the Robinson-Goforth topology... |
| **STACKFEED: Structured Textual Actor-Critic Knowledge Base Editing with FeedBack** | Microsoft Research | This presents an interesting reversal of thinking... |
| **Embedding Self-Correction as an Inherent Ability in Large Language Models for Enhanced Mathematical Reasoning** | Tencent | This work employs OpenCodeInterpreter and Self-Improvement for mathematical applications... |
| **AFlow: Automating Agentic Workflow Generation** | DeepWisdom, The Hong Kong University of Science and Technology (Guangzhou) | The author expresses personal disinterest... |
| **VideoAgent: Self-Improving Video Generation** | University of Waterloo, IIT Kharagpur, Google Deepmind | This work focuses on self-improving video generation based on external feedback... |
| **OpenR: An Open Source Framework for Advanced Reasoning with Large Language Models** | University College London, University of Liverpool, Shanghai Jiao Tong University | This work is framework-oriented, solid, and worth investigating... |
| **Alignment Between the Decision-Making Logic of LLMs and Human Cognition: A Case Study on Legal LLMs** | University of Geneva, Google DeepMind, √âcole Normale Sup√©rieure | This framework evaluates multi-step CoT generation and LLM judgment abilities... |
| **Mechanistic Interpretability for AI Safety: A Review** | University of Amsterdam | Basic overview of mechanical interpretability concepts... |
| **Zero-shot Commonsense Reasoning over Machine Imagination** | - | This study generates text QA pairs from a knowledge base... |
| **Two Heads Are Better Than One: A Multi-Agent System Has the Potential to Improve Scientific Idea Generation** | Shanghai Artificial Intelligence Laboratory | This concept is intriguing and enjoyable, resembling a sci-fi novel... |
| **HART: Efficient Visual Generation with Hybrid Autoregressive Transformer** | MIT, NVIDIA, Tsinghua University | This autoregressive diffusion-based image generation model is highly recommended for review... |
| **LVD-2M: A Long-take Video Dataset with Temporally Dense Captions** | The University of Hong Kong, ByteDance | Congratulations on this valuable synthetic long video generation dataset!... |
| **TemporalBench: Benchmarking Fine-grained Temporal Understanding for Multimodal Video Models** | University of Wisconsin-Madison, Microsoft Research | This benchmark is highly valuable for video understanding, though a bit brief... |
| **Introducing an Improved Information-Theoretic Measure of Predictive Uncertainty** | Johannes Kepler University Linz | The author hasn't yet had time to thoroughly examine the formulas but intends to... |
| **When Attention Sink Emerges in Language Models: An Empirical View** | Sea AI Lab, National University of Singapore | Highly recommended reading. Key takeaways include... |
| **Deep Compression Autoencoder for Efficient High-Resolution Diffusion Models** | MIT, Tsinghua University, NVIDIA | This approach is simple and effective, using residual connections to address... |
| **SeedLM: Compressing LLM Weights into Seeds of Pseudo-Random Generators** | Apple, Meta | This training-free model compression method aligns well with fine-grained MoE strategies... |
| **Adapt-‚àû: Scalable Lifelong Multimodal Instruction Tuning via Dynamic Data Selection** | UNC Chapel Hill | This data selection method can also be applied to text SFT... |
| **BookWorm: A Dataset for Character Description and Analysis** | University of Edinburgh | This dataset may be quite important for role-playing... |
| **Evaluating Semantic Variation in Text-to-Image Synthesis: A Causal Perspective** | Fudan University, HKU (Guangzhou) | This new benchmark measures the causal impact of semantic variations... |
| **Predicting from Strings: Language Model Embeddings for Bayesian Optimization** | UCLA, Google DeepMind, Google | This work explores embeddings of experimental inputs... |
| **LOBG: Less Overfitting for Better Generalization in Vision-Language Models** | Xi‚Äôan Jiaotong University | This study improves generalization capabilities of vision-language models... |
| **Œ±-DPO: Adaptive Reward Margin is What Direct Preference Optimization Needs** | University of Science and Technology of China | The author plans to review the formulas for this paper... |
| **FormalAlign: Automated Alignment Evaluation for Autoformalization** | HKU, Cambridge, Huawei Noah's Ark Lab | The issues addressed in this paper are significant... |
| **Scalable Multi-Domain Adaptation of Language Models using Modular Experts** | UC Berkeley, Google | The proposed method is worth researching for edge applications... |
| **Collu-Bench: A Benchmark for Predicting Language Model Hallucinations in Code** | Purdue University | This benchmark addresses valuable problems related to hallucinations in code... |
| **Retrieval Instead of Fine-tuning: A Retrieval-based Parameter Ensemble for Zero-shot Learning** | Massachusetts General Hospital, Harvard Medical School | Similar to previous work on retrieval-based ensembles... |
| **Gradient-Free Neural Network Training on the Edge** | Bosch Centre for AI | The gradient-free training approach involves flipping related nodes... |
| **MoIN: Mixture of Introvert Experts to Upcycle an LLM** | - | Similar to the previous one... |
| **Can In-context Learning Really Generalize to Out-of-distribution Tasks?** | Peiking University, MIT | The experiments are solid, with conclusions similar to Jiaoda Li's paper... |
| **Reconstructive Visual Instruction Tuning** | Chinese Academy of Sciences | This introduces reconstructive visual instruction tuning, enhancing LMMs... |
| **Boosting Deductive Reasoning with Step Signals In RLHF** | Baichuan AI | Not reviewed yet, noted for future reference... |
| **MIRAGE: Evaluating and Explaining Inductive Reasoning Process in Language Models** | Chinese Academy of Sciences | This benchmark was forwarded to Yang Guang and Peng Tao... |
| **Fine-grained Attention I/O Complexity: Comprehensive Analysis for Backward Passes** | Stevens Institute of Technology, UC Berkeley, University of Wisconsin-Madison, University of Pennsylvania | Noted for future reference... |
| **SeRA: Self-Reviewing and Alignment of Large Language Models using Implicit Reward Margins** | KAIST AI, Amazon | ... |
| **Inference and Verbalization Functions During In-Context Learning** | Stanford University | ... |
| **Nudging: Inference-time Alignment via Model Collaboration** | UC Irvine | ... |
| **Enhancing Multi-Step Reasoning Abilities of Language Models through Direct Q-Function Optimization** | ByteDance | ... |
| **One Step at a Time: Combining LLMs and Static Analysis to Generate Next-Step Hints for Programming Tasks** | JetBrains Research | ... |
| **The Same But Different: Structural Similarities and Differences in Multilingual Language Modeling** | Brown University | ... |
| **Automated Rewards via LLM-Generated Progress Functions** | Stanford University | ... |
| **ACER: Automatic Language Model Context Extension via Retrieval** | CMU, UIUC | ... |
| **REDO: Execution-Free Runtime Error Detection for Coding Agents** | University of Pennsylvania | ... |
| **Focus on Your Question! Interpreting and Mitigating Toxic CoT Problems in Commonsense Reasoning** | University of Chinese Academy of Sciences | ... |
| **DARE the Extreme: Revisiting Delta-Parameter Pruning For Fine-Tuned Models** | University of British Columbia | ... |


</table>


## üõ†Ô∏è Papers This Week 

(Expand to View)

<details>
<summary> <b>14/10/2024</b> </summary>

<table class="center">

| Paper | Affiliation | Comments |
|:-------------|:-------------|:-------------|
| Editing Massive Concepts in Text-to-Image Diffusion Models | HKU, THU | Editing Massive Concepts in Text-to-Image Diffusion Models addresses the problem of scalable batch image editing based on concepts. However, the approach does not appear to be particularly robust. The authors have collected 1,000 potentially problematic concepts, which are meaningful, but there is uncertainty regarding how this method is intended to be applied in practical scenarios. To effectively avoid issues such as copyright infringement, bias, or factual inaccuracies in generated outputs, the model first needs to recognize when an error has occurred before it can take steps to correct it. This is the critical challenge. Diffusion-based models do not seem to possess a strong concept-based understanding of the world. The current solution appears to rely on continuously patching problems, which is not a sustainable long-term strategy. However, the approach could be useful in preventing the generation of copyrighted images. That being said, ideally, models should not be trained on copyrighted images in the first place. Additionally, the paper does not provide experimental validation for the issue of model collapse. There is room for the method to be more rigorous. The ICEB (Image Concept Editing Benchmark) used to evaluate concept-based image editing is a valuable contribution‚Äîsuch a large-scale benchmark has not been seen before. |
| Promptly Yours? A Human Subject Study on Prompt Inference in AI-Generated Art | University of Oklahoma, University of Texas | Figures 11-14 are particularly interesting. They highlight that diffusion models haven't generalized well from the original prompts to the generated images. In fact, neither humans nor AI are able to recall the original prompts accurately. |
| KV Prediction For Improved Time to First Token | Apple | Apple has recently released several intriguing works. One of them uses a small model to predict approximate values for the KV-cache of a larger model. There was a previous proposal, which wasn‚Äôt implemented, that suggested using a small model to predict which experts in a Mixture of Experts (MoE) model might activate based on the input tokens. However, it was reconsidered due to the time cost of loading and unloading experts. The advantage of this approach would be the potential to use a larger MoE model with limited GPU memory. Furthermore, it is unclear whether the KVP-C and KVP-LP methods suggest that models of different sizes, trained on the same data, learn robust activation patterns. Even after pruning or when working with models of varying sizes, the activation patterns seem to remain largely consistent. |
| UNIQ: Offline Inverse Q-learning for Avoiding Undesirable Demonstrations | Singapore Management University | The writing is solid, and the motivation is clear. The issue of sparse expert data in offline imitation learning is real. Instead of minimizing the distance to expert data, the paper proposes maximizing the distance between undesirable demonstrations, which seems like a straightforward idea, particularly for RLHF (Reinforcement Learning from Human Feedback). It‚Äôs unclear if this has been explored before; a more thorough survey could be done in the future, along with revisiting the formulas. It's worth marking for further investigation. |
| Can Looped Transformers Learn to Implement Multi-step Gradient Descent for In-context Learning? | Google Research | This work is a well-executed study on mechanical interpretability using synthetic data. However, it suffers from a common issue in such research‚Äîthe lack of in-depth data analysis, as most of the conclusions are qualitative rather than quantitative. The qualitative finding is that a single-layer Transformer can express multi-step algorithms, which is extended to show that multi-layer Transformers can learn multi-step algorithms. While this is a solid contribution, it doesn't provide a deep understanding of how multi-step algorithms are reflected in the model's parameters. Additionally, the paper demonstrates generalization to out-of-distribution (OOD) algorithms. The model was trained with data using a unit covariance matrix but tested with different covariance matrices, and the looped transformers still managed to achieve low loss, indicating strong generalization across distributions. This raises a hypothesis that pre-training may also involve learning many such algorithmic loops, where multi-hop reasoning could be seen as a form of algorithm. If these parts of the model parameters could be activated‚Äîsuch as in cases where data encoded as code has learned a divide-and-conquer method‚Äîthere‚Äôs potential for such reasoning to generalize to broader data. However, this would require the correct activation of attention heads without overfitting to input patterns. This is recommended reading. |
| Koala-36M: A Large-scale Video Dataset Improving Consistency between Fine-grained Conditions and Video Content | Kuaishou Technology, Shenzhen University, Tsinghua University | This appears to be a highly valuable video dataset, and it seems a significant amount of money was invested in it. Further research is recommended. |
| Baichuan-Omni Technical Report | Baichuan Inc, Westlake University | Baichuan continues to justify its work in pre-training, which appears somewhat basic. The text performance is underwhelming. However, there could be some valuable insights regarding how the encoder is handled. The use of a projector following the visual encoder might improve the efficiency and effectiveness of converting visual input into semantic tokens, and it seems reasonable overall. Stage 2 involves adding synthetic QA and high-quality OCR, which is in line with how others retrain CLIP. If this approach could replace the need to retrain CLIP and caption models, it would be quite valuable. The audio method, which seems to be based on the early understanding of audio being processed similarly to images, is less convincing. It‚Äôs disappointing that the paper didn‚Äôt test on OmniBench. |
| SimpleStrat: Diversifying Language Model Generation with Stratification | UC Berkeley | This work provides a quantitative assessment of whether models can respond diversely from multiple perspectives. They designed a benchmark, ConvergeQA, which shows an average of 28 possible answers. This could help verify if a model tends to favor depth-first and fixed patterns or if it is more inclined toward exploration. It seems like an interesting observation benchmark and is recommended for further reading. |
| Agents Thinking Fast and Slow: A Talker-Reasoner Architecture | Google DeepMind | Google‚Äôs agent framework seems unremarkable, with no groundbreaking metrics. However, the behavioral pattern of a ‚Äútalker‚Äù directing a ‚Äúreasoner‚Äù to verify each intermediate step has been evident in earlier work, such as HotpotQA, Collie, AIME, Usaco, and LiveCodeBench. Collie is an outlier, where, in 50 sampled examples, no pre-planned thought was observed, while the other four benchmarks displayed consistent patterns of divide-and-conquer (COT) or retrieving potential pre-existing solutions (UKM). The intriguing part of this experiment is the high degree of convergence in thought patterns within each benchmark. The question remains whether the model learned this behavior or if it simply reflects rigid synthetic data. The latter seems more likely. For instance, in USACO and LiveCodeBench, divide-and-conquer appeared far more frequently than retrieval-based thinking (UKM), even though template-based approaches are common for humans. Additionally, the consistency of thought patterns within each benchmark supports this hypothesis. Returning to this paper, the talker-reasoner approach could potentially represent a fixed pattern in generating similar data in models like o1. |
| ‚àÄuto‚àÉ‚à®‚àßL: Autonomous Evaluation of LLMs for Truth Maintenance and Reasoning Tasks | Arizona State University | This could serve as a scalable fluid intelligence benchmark. |
| NoVo: Norm Voting off Hallucinations with Attention Heads in Large Language Models | - | This research explores controlling behavior by manipulating attention heads during inference. It‚Äôs an intriguing concept, though the use of this method to address multiple-choice questions (MCQs) feels a bit underwhelming. It‚Äôs disappointing that domestic researchers are focusing on leaderboard-hacking; at the very least, MMLU should have been used as a benchmark. |
| The Structure of the Token Space for Large Language Models | American University | The paper argues that token subspace is a stratified manifold rather than a manifold. However, the experiments do not seem particularly robust. It‚Äôs unclear what practical significance this conclusion has, so it‚Äôs worth marking for future consideration. |
| Towards Cross-Lingual LLM Evaluation for European Languages | TU Dresden, Fraunhofer IAIS | This is a benchmark collection for European minor languages. |
| CryoFM: A Flow-based Foundation Model for Cryo-EM Densities | Bytedance Research | - |
| VERIFIED: A Video Corpus Moment Retrieval Benchmark for Fine-Grained Video Understanding | Tsinghua University | This is a challenging benchmark for fine-grained video moment retrieval, refining coarse-grained image descriptions into those with more precise detail. It increases the level of difficulty in matching descriptions to specific frames. |
| PoisonBench: Assessing Large Language Model Vulnerability to Data Poisoning | Renmin University of China, Anthropic | It‚Äôs surprising to see a paper co-authored by Anthropic and Renmin University. The three key takeaways are intriguing: (1) Scaling up parameter size does not inherently enhance resilience against poisoning attacks; (2) There is a log-linear relationship between the effects of the attack and the data poison ratio; (3) Data poisoning effects can generalize to triggers not included in the poisoned data. Recommended reading. |
| On the Token Distance Modeling Ability of Higher RoPE Attention Dimension | Tsinghua University, Tencent Inc | This is a valuable read that analyzes the contribution of various RoPE dimensions to attention heads, identifying positional heads. Figure 9 shows that the top 10% of heads are active, and masking them leads to greater loss than masking the top 5%. This is worth considering in relation to the sparsity of head activation during LLM inference. For long-text cases, it might be necessary to activate more heads. The analysis reveals that the high-dimensional components of most attention heads contribute more to the attention score. The method for extending attention distribution in long texts is worth further exploration. |
| ZipVL: Efficient Large Vision-Language Models with Dynamic Token Sparsification and KV Cache Compression | Zhejiang University, Shanghai AI Laboratory | This paper discusses dynamically determining the proportion of tokens based on attention scores during the pre-filling stage, using only important tokens. It‚Äôs seamlessly compatible with existing frameworks. This direction could be highly relevant for long video understanding, as there is often a lot of redundant information. Further research is warranted. |
| Scaling Laws for Predicting Downstream Performance in LLMs | University of Illinois Urbana-Champaign, Amazon | The solution does not directly optimize for the inability to fit downstream performance, and the understanding of downstream datasets' distribution is limited. Section 5.1‚Äôs formula is worth investigating. One promising direction is how to segment and fine-tune pre-training data to save on experimental costs. It references a comment: ‚ÄúFrom an efficiency perspective during inference time, using MLP or a more advanced model for regression would be a better choice; lightgbm + simulation has some flaws.‚Äù Fine-tuning learning rate and data schedulers could also be valuable. The paper references a technique where high-quality data is upsampled during the final stages of training (the annealing phase) to boost performance without introducing new data. This approach contrasts with MiniCPM, as it only upsampled existing data but still improved results. Data mixtures might not be fixed ratios either. If unfamiliar with data mixture laws, this paper is worth reading, along with D-CPT Law, RegMix, and a recent paper from Amazon that applies this concept outside of LLMs. |


</table>

</details>

<hr/>

If you are intereted in the work published by us, please navigate to our [full paper list](https://huggingface.co/collections/m-a-p/m-a-p-full-paper-list-65e070a694c7b01c5547fbff).
