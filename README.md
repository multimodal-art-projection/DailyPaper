<h1 align="center"><img src="https://cdn-avatars.huggingface.co/v1/production/uploads/63839e9962badff4326cf360/k4Q7R4XLDMp_1VF4C6GEd.jpeg" width="25"> M-A-P Daily Paper</h1>
<p align="center">
<a href="https://github.com/DenverCoder1/readme-typing-svg"><img src="https://media.giphy.com/media/Rn26lWjqA0uUU/giphy.gif" width="100"></a>
</p>
<hr/>
<h4 align="center">The <a href=https://m-a-p.ai>M-A-P</a> daily paper project curates and reviews a selection of new papers published daily on arXiv, providing insightful commentary on cutting-edge research across various scientific disciplines.</h4>
<br>

[Click to view previous selection](https://m-a-p.ai/DailyPaper/archived_papers.html).

<hr/>

## üî• Paper Today: 17/10/2024

<table class="center">

| Paper | Comments |
|:-------------|:-------------|
| OmnixR: Evaluating Omni-modality Language Models on Reasoning across Modalities | The researcher recommends their OmniBench and shares insights gained from three to four months of dedicated evaluation experience. They suggest that insightful evaluations should naturally possess certain characteristics in data organization: 1) Avoid coupling between model capabilities, focusing on issues that can be improved through architecture or data but may be blind spots. 2) Design evaluation sets for genuinely universal problems, including future issues, but not non-universal ones. 3) Cognitive science concepts are crucial, offering many valuable evaluation perspectives. 4) Evaluations should not fear being solved quickly; benchmarks are consumables designed to guide model improvements, fulfilling their historical mission by identifying issues. |
| Proactive Agent: Shifting LLM Agents from Reactive Responses to Active Assistance | The researcher highly endorses this direction, viewing it as an area where academia can continually accumulate value with measurable outputs from investments. The most valuable general insights involve LLMs' basic abilities, proactively seeking information and simple Agent Instruct capabilities. By continuously summarizing and forming general workflow paths to solve problem types, robust synthetic environments can generate numerous workflows with potential practical value for platforms like Coze or Difny. However, the researcher suggests that while generating workflows is valuable, dedicating efforts to reinforcement learning might be unnecessary at this stage. |
| PRefLexOR: Preference-based Recursive Language Modeling for Exploratory Optimization of Reasoning and Agentic Thinking | The researcher finds this paper, written by an MIT PI in materials science, interesting. It presents an O1-like system concept with several insightful elements, such as using ORPO for iteration, dynamic knowledge graphs, and the notion of thinking tokens, which might serve a function similar to tone words in O1. The researcher humorously adds a citation review: "Identified as aspiring for a Nobel Prize in Physics." |
| Revealing the Barriers of Language Agents in Planning | The researcher acknowledges Blocksworld and TravelPlanner as excellent datasets, suggesting the inclusion of TravelPlanner in the OOD bench due to its wide recognition. Key takeaways align with their internal findings: current open-source models tend to follow instruction intent coarsely rather than decomposing and strictly adhering to complex composite instructions, struggling with combinations. This is identified as a key capability requiring attention. The definitions of episodic memory and parametric memory are also noted as interesting. |
| JudgeBench: A Benchmark for Evaluating LLM-based Judges | The researcher views this as a correct direction, leaning more towards Factuality and Complex Reasoning compared to RewardBench. It is seen as an effective supplement for analyzing Reward Modeling effects. |
| DDIL: Improved Diffusion Distillation With Imitation Learning | - |
| MoE-Pruner: Pruning Mixture-of-Experts Large Language Model using the Hints from Its Router | - |
| Open Domain Question Answering with Conflicting Contexts | The researcher identifies this as a valuable Reasoning Benchmark that incorporates Conflict Context. |
| Understanding the Role of LLMs in Multimodal Evaluation Benchmarks | The researcher acknowledges MMMU's limitations, noting that most questions can be answered without vision-related world knowledge. This insight is deemed important for benchmark design, emphasizing the need to strictly consider whether visual input is necessary, whether spatial awareness is required, or if text descriptions suffice. Three levels of benchmarks are proposed: no visual need, visual need without spatial awareness, and essential spatial awareness. |
| HumanEval-V: Evaluating Visual Understanding and Reasoning Abilities of Large Multimodal Models Through Coding Tasks | The researcher recommends integrating this multimodal coding benchmark into internal visual benchmarks. |
| Is Complex Query Answering Really Complex? | The researcher finds the paper's breakdown of partial reasoning queries versus full reasoning queries significant for language model benchmarks. They suggest that applying this decomposition to problems like HotpotQA could yield valuable insights into the proportion of reasoning versus memorized components in long chain-of-thought solutions. |
| WorldCuisines: A Massive-Scale Benchmark for Multilingual and Multicultural Visual Question Answering on Global Cuisines | - |
| A Scalable Communication Protocol for Networks of Large Language Models | The researcher distills the core insight: frequent communications are handled through traditional protocols, infrequent ones through structured data exchange, and rare communications use natural language. They agree with this approach, advocating for systems that utilize LLMs appropriately without assigning unnecessary active roles for the sake of being fancy. |
| Identifying Task Groupings for Multi-Task Learning Using Pointwise V-Usable Information | The researcher sees potential in adapting this as an indicator for controlling SFT data distribution. They suggest exploring methods from multi-task learning task number scaling for potentially useful approaches. |
| Counterfactual Generative Modeling with Variational Causal Inference | - |
| Exploring Model Kinship for Merging Large Language Models | The researcher finds this paper interesting, defining a new direction in model kinship. They suggest broader applications beyond model merging and note areas for improvement, such as considering inter-layer differences and robustness across different architectures. They propose extending the concept to define cross-model kinship based on semantic similarities of head patterns and activation patterns in complex reasoning cases. |
| Rethinking Visual Counterfactual Explanations Through Region Constraint | The researcher marks this for later reading, noting that the Automated Region Extraction step seems non-essential and abrupt. They find other parts of the definition self-consistent based on their limited diffusion knowledge and plan to study it more carefully later. |
</table>


## üõ†Ô∏è Papers This Week 

(Expand to View)
<details>
<summary> <b>15/10/2024</b> </summary>

<table class="center">

| Paper | Comments |
|:-------------|:-------------|
| TMGBench: A Systematic Game Benchmark for Evaluating Strategic Reasoning Abilities of LLMs | TMGBENCH includes 144 types of games based on Robinson-Goforth topologies, each containing multiple instances. These games can be further organized into sequential, parallel, and nested forms. Evaluation metrics are designed, effectively reflecting fluid intelligence and dynamic scalability. Similar to previous benchmarks, a decisive gap between open-source models and models like Claude and GPT-4 was observed. Forwarded to @Peng Tao @Yang Guang. Model behavior traits may be critical, as BoN's ability to select good cases depends on sufficient sampling diversity. However, open-source models lack dynamic thinking, possibly making inference scaling harder for these models. Highly recommended for reading, with an emphasis on improving dynamic pattern composition. |
| STACKFEED: Structured Textual Actor-Critic Knowledge Base Editing with FeedBack | A reverse thinking approach, where instead of using Actor-Critic to modify LLM, it is used to modify KB. This makes a lot of sense. Such reverse thinking seems much needed. |
| Embedding Self-Correction as an Inherent Ability in Large Language Models for Enhanced Mathematical Reasoning | Developed by Tencent, this combines OpenCodeInterpreter with self-improvement for math, though it's fairly average. Many methods introducing strong verifiers to support CoT already exist. |
| AFlow: Automating Agentic Workflow Generation | Personally, I'm not fond of using an agent workflow to solve all problems, but this paper feels like an exception with fundamental value. The abstraction suggests that if a specific workspace definer exists, it could sequentially sample and generate workspace descriptions. This has high theoretical value for frameworks like Coze and Difny. Recommended for follow-up. |
| VideoAgent: Self-Improving Video Generation | This tackles video generation with self-improvement based on external feedback, though it was only tested in robotic scenarios using MetaWorld, iTHOR, and BridgeData V2 datasets. Limited knowledge in this field makes it hard to confirm whether the title might be an overclaim, as "AIGC" comes to mind. |
| OpenR: An Open Source Framework for Advanced Reasoning with Large Language Models | A framework with extensive support according to the paper, including PRM support for scoring and strategy selection. Key formalizations are generalizable, with few unconventional techniques. Its practical usability may depend on ease of use. Worth exploring. |
| Alignment Between the Decision-Making Logic of LLMs and Human Cognition: A Case Study on Legal LLMs | An evaluation framework for step-wise CoT generation quality, which defines irrelevant, incorrect, and correct tokens. It could extend to a framework for evaluating BoN/MCTS/CoT performance by measuring step repetition, CoT reliability, and search space. The interaction framework feels unnecessary. |
| Mechanistic? | A primer on mechanical interpretability, offering a historical overview. It could be a worthwhile read for those interested in the basics. |
| Zero-shot Commonsense Reasoning over Machine Imagination | Involves generating text QA pairs from a knowledge base, followed by text-to-image generation for a VQA dataset. An intern's project that aligned CLIP embeddings but seemed scooped. Though it improves commonsense reasoning, the work isn't particularly solid. Issues with SFT and pretraining data alignment are worth further exploration. |
| Two Heads Are Better Than One: A Multi-Agent System Has the Potential to Improve Scientific Idea Generation | Reads like a science fiction story, but it's quite fun. The idea of generating a digital researcher and simulating collaborative research sounds interesting. It raises curiosity about personal digital researcher performance. |
| HART: Efficient Visual Generation with Hybrid Autoregressive Transformer | MIT's autoregressive diffusion-based image generation model. Strongly recommended for a detailed read. |
| LVD-2M: A Long-take Video Dataset with Temporally Dense Captions | Congrats! This synthetic long video generation data is highly valuable. |
| TemporalBench: Benchmarking Fine-grained Temporal Understanding for Multimodal Video Models | A valuable benchmark for video understanding. However, the videos might be too short, with the longest ones under 10 minutes. The study found that performance saturates at 8-16 frames, which is a key takeaway. Recommended reading. |
| On Information-Theoretic Measures of Predictive Uncertainty | Haven't had the chance to study the formulas thoroughly. Marked for later review. Transformation between Equation 1 and 5 seems fine. These measures might be critical for improving preference data efficiency. |
| When Attention Sink Emerges in Language Models: An Empirical View | Highly recommended reading. Although the sample size isn't large, the experiments are rigorous. Key takeaways: (1) weight decay encourages attention sinks, (2) larger training datasets exacerbate attention sinks, (3) random and repeated sequences influence attention sinks. This supports sentence-level deduplication and the removal of random sequences. |
| Deep Compression Autoencoder for Efficient High-Resolution Diffusion Models | Simple and effective method using residuals and decoupling high-resolution adaptation to solve reconstruction accuracy issues. The approach feels like broadening the information bottleneck. Highly recommended for reading. |
| SeedLM: Compressing LLM Weights into Seeds of Pseudo-Random Generators | Training-free model compression method without calibration data. Introduces bypass parameters to reconstruct weight blocks, aligned with MoE fine-grained compression thoughts. |
| Adapt-‚àû: Scalable Lifelong Multimodal Instruction Tuning via Dynamic Data Selection | The idea of dynamically selecting and pooling new SFT data is a good system demo concept, although it feels underdeveloped. Recommended reading. |
| BookWorm: A Dataset for Character Description and Analysis | Potentially important for role-playing, containing character descriptions and in-depth analysis with high confidence. |
| Evaluating Semantic Variation in Text-to-Image Synthesis: A Causal Perspective | An interesting new benchmark that measures the causal effects of semantic variation in text-to-image models. The key takeaway: cross-modal alignment in UNet or Transformers is critical, and text encoder capability isn't the sole determining factor. |
| Predicting from Strings: Language Model Embeddings for Bayesian Optimization | GDM's exploratory work using language model embeddings for Bayesian optimization. Larger models perform better, showing higher capacity and better inductive bias. |
| LOBG: Less Overfitting for Better Generalization in Vision-Language Model | Through fine-grained filtering and hierarchical logic distillation, this study improves vision-language model generalization. Although there is high exploratory value, the approach feels basic. |
| Œ±-DPO: Adaptive Reward Margin is What Direct Preference Optimization Needs | Marked for formula review. |
| FormalAlign: Automated Alignment Evaluation for Autoformalization | Addressing formalization issues in lean translation. Current metrics lack persuasiveness. Semantic analysis in this context is questionable. |
| Scalable Multi-Domain Adaptation of Language Models using Modular Experts | An early 2023 project on modular expert systems with a very rough implementation. It aligns with the idea of training multiple experts and using a routing system for unseen tasks. The approach has potential for edge-side research. |
| Collu-Bench: A Benchmark for Predicting Language Model Hallucinations in Code | A valuable benchmark addressing hallucination in code generation. The key takeaway: keywords, identifiers, and type identifiers are most prone to hallucination. |
| Retrieval Instead of Fine-tuning: A Retrieval-based Parameter Ensemble for Zero-shot Learning | Similar to another paper, it offers a retrieval-based parameter ensemble for zero-shot learning. |
| Gradient-Free Neural Network Training on the Edge | A gradient-free training method. A quick glance shows that gradient replacement involves an intermediate tensor. |
| MoIN: Mixture of Introvert Experts to Upcycle an LLM | Similar to a previous paper, exploring introvert experts for LLM. |
| Can In-context Learning Really Generalize to Out-of-distribution Tasks? | Solid experiments but similar to a previous paper, showing ICL mainly retrieves implicit functions from pretraining. |
| Reconstructive Visual Instruction Tuning | By introducing reconstructive visual instruction tuning, this significantly improves fine-grained understanding in LMMs and reduces hallucination. It aims to balance low-level visual information, though it feels somewhat esoteric. |
| Boosting Deductive Reasoning with Step Signals In RLHF | - |
| MIRAGE: Evaluating and Explaining Inductive Reasoning Process in Language Models | Potentially a good benchmark for evaluating fluid intelligence. |
| Fine-grained Attention I/O Complexity: Comprehensive Analysis for Backward Passes | A detailed analysis of attention mechanism I/O complexity. Worth revisiting. |

</table>

</details>

<hr/>

<details>
<summary> <b>14/10/2024</b> </summary>

<table class="center">

| Paper | Comments |
|:-------------|:-------------|
| Editing Massive Concepts in Text-to-Image Diffusion Models | This paper addresses scalable concept-based image batch editing but lacks solid grounding. It presents the collection of 1,000 potentially problematic concepts, a meaningful issue, but it's unclear how the method can be applied in practice. To avoid copyright issues, bias, or factual errors in outputs, models first need to recognize these errors, which seems critical. Diffusion-based models don't appear to have deep concept-based world understanding, and merely patching the system isn't sustainable. However, it could potentially avoid generating copyrighted images, though copyright images shouldn't be used for training in the first place. There is also no experimental validation for model collapse issues, which could be more rigorously addressed. The ICEB benchmark for concept-based image editing detection is valuable, the largest seen so far. |
| Promptly Yours? A Human Subject Study on Prompt Inference in AI-Generated Art | Figures 11-14 are particularly interesting, demonstrating that Diffusion models haven't generalized well from the original prompts to generated images. Both humans and AI fail to recall the original prompt. |
| KV Prediction for Improved Time to First Token | Apple has produced several intriguing works recently. This one uses a small model to predict the actual model‚Äôs KV-cache approximation. There was a previous idea, though unimplemented, proposing a small model to predict which experts in MoE might activate based on the input token. However, frequent loading and unloading of experts is time-consuming. The advantage here could be the use of larger MoEs with smaller memory footprints. The KVP-C and KVP-LP findings suggest that different-sized models, even after pruning, learn remarkably robust activation patterns for the same dataset. |
| UNIQ: Offline Inverse Q-learning for Avoiding Undesirable Demonstrations | Well-written with clear motivation. Offline imitation learning often faces expert data scarcity, so maximizing the distance between many undesirable demonstrations rather than minimizing it with expert data is a novel approach. This is a seemingly intuitive idea for RLHF as well. It warrants further survey and mathematical exploration. A promising direction. |
| Can Looped Transformers Learn to Implement Multi-step Gradient Descent for In-context Learning? | A robust work based on synthetic data in mechanical interpretability. However, like similar works, it lacks deeper data analysis, focusing more on qualitative than quantitative results. It successfully demonstrates that multi-layer transformers can learn multi-step algorithms, but the understanding of how these algorithms manifest in model parameters remains shallow. The work also verifies some out-of-distribution generalizations, as looped transformers retained low losses despite different covariance matrices used in training and testing. This raises the possibility that transformers, trained on diverse algorithmic loops, might generalize higher-level reasoning if the right parameters can be activated. |
| Koala-36M: A Large-scale Video Dataset Improving Consistency between Fine-grained Conditions and Video Content | A potentially very useful video dataset, likely expensive to collect, and warrants further investigation. |
| Baichuan-Omni Technical Report | Baichuan seems to continue pretraining with toy tasks. Text performance remains lacking, though some parts of the encoder are worth exploring for their potential value. The visual encoder's use of a projector to enhance semantic token conversion efficiency appears reasonable. Stage 2 involves synthetic QA and high-quality OCR, which mirrors traditional retraining of CLIP models. If this can replace training a new CLIP or caption model, it‚Äôs valuable. The audio processing method still relies on the early understanding of treating audio as images, a point of personal disagreement. No OmniBench tests, unfortunately. |
| SimpleStrat: Diversifying Language Model Generation with Stratification | The work quantifies whether models can generate diverse responses from multiple perspectives, testing on ConvergeQA with an average of 28 answers. This might verify whether models prefer deep-search rigid modes or exploration. It's an interesting benchmark observation worth forwarding to colleagues for further reading. |
| Agents Thinking Fast and Slow: A Talker-Reasoner Architecture | Google's agent framework appears unremarkable in terms of metrics, yet the pattern of a talker guiding a reasoner to verify each step is evident. In a prior experiment with various benchmarks (HotpotQA, Collie, AIME, etc.), O1 showed no pre-planned thought examples for Collie, unlike others, which followed a consistent thought pattern. This raises the question: are these agent steps a reflection of learned fixed patterns from synthetic data? A thought-provoking area. |
| ‚àÄuto‚àÉ‚à®‚àßL: Autonomous Evaluation of LLMs for Truth Maintenance and Reasoning Tasks | A scalable fluid intelligence benchmark candidate. Recommended for colleagues. |
| NoVo: Norm Voting off Hallucinations with Attention Heads in Large Language Models | Interesting work on controlling behavior patterns through attention heads during inference. However, using this for multiple-choice questions feels underwhelming, a common practice among certain research groups. |
| The Structure of the Token Space for Large Language Models | The paper posits that the token subspace is a stratified manifold rather than a manifold. The experiments don‚Äôt feel particularly solid, leaving the practical utility of the conclusion unclear for now. |
| Towards Cross-Lingual LLM Evaluation for European Languages | A European benchmark collection for lesser-spoken languages. Noted as a valuable resource for colleagues. |
| CryoFM: A Flow-based Foundation Model for Cryo-EM Densities | - |
| VERIFIED: A Video Corpus Moment Retrieval Benchmark for Fine-grained Video Understanding | A challenging benchmark refining coarse-grained image descriptions into fine-grained ones, adding more precision and difficulty in corresponding descriptions to frames. |
| PoisonBench: Assessing Large Language Model Vulnerability to Data Poisoning | A rare collaboration between Anthropic and Renmin University, with three notable takeaways: (1) Scaling up model parameters does not necessarily enhance resistance to poisoning; (2) There‚Äôs a log-linear relationship between the attack effect and poison ratio; (3) Poisoning can generalize to triggers not seen in the poisoned data. Recommended reading. |
| On the Token Distance Modeling Ability of Higher RoPE Attention Dimension | A highly valuable read. It analyzes which RoPE dimensions contribute to attention heads, positioning positional heads effectively. Figure 9 shows that masking the top 10% of heads causes a significant loss compared to masking 5%, which has implications for sparsity in attention activation during long-text cases. |
| ZipVL: Efficient Large Vision-Language Models with Dynamic Token Sparsification and KV Cache Compression | Initial observations suggest the work uses attention scores to dynamically determine token ratios, filling only the important ones during prefill stages. This is a meaningful direction, especially for long video understanding, as it addresses the redundancy issue. Worth further investigation. |
| Scaling Laws for Predicting Downstream Performance in LLMs | The proposed solution does not optimize the actual issue of fitting downstream performance. The formula in section 5.1 is worth analyzing, with the main value being cost-saving on experiments. Insights from comments suggest that more granular control over learning rates and data schedulers could improve efficiency. The idea of increasing high-quality data proportion during the final training phase echoes earlier practices. While not introducing new data, this upsampling still boosts performance. Worth reading alongside works on data mixture laws. |


</table>

</details>

<hr/>

If you are intereted in the work published by us, please navigate to our [full paper list](https://huggingface.co/collections/m-a-p/m-a-p-full-paper-list-65e070a694c7b01c5547fbff).
