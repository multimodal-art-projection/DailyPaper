<h1 align="center"><img src="https://cdn-avatars.huggingface.co/v1/production/uploads/63839e9962badff4326cf360/k4Q7R4XLDMp_1VF4C6GEd.jpeg" width="25"> M-A-P Daily Paper</h1>
<p align="center">
<a href="https://github.com/DenverCoder1/readme-typing-svg"><img src="https://media.giphy.com/media/Rn26lWjqA0uUU/giphy.gif" width="100"></a>
</p>
<hr/>
<h4 align="center">The <a href=https://m-a-p.ai>M-A-P</a> daily paper project curates and reviews a selection of new papers published daily on arXiv, providing insightful commentary on cutting-edge research across various scientific disciplines.</h4>
<br>
<hr/>

[back to main page](https://m-a-p.ai/DailyPaper)

## üõ†Ô∏è Papers This Week 

(Expand to View)

<details>
<summary> <b>11/10/2024</b> </summary>

<table class="center">

| Paper | Comments |
|:-------------|:-------------|
| Zero-Shot Generalization of Vision-Based RL Without Data Augmentation | Generalization of vision-based agents in new environments (cross-game environments) is a research topic worth long-term investment. While humans can quickly adapt to new games by reading instructions, models require significant training time or strong supervision via "external knowledge." The common approach usually involves a memory module, which can be disentangled representations from vision (like this paper) or text-based/shared state spaces (e.g., controller operations). The user worked on this topic around a year ago with projects like MORE-3S: Multimodal-based Offline Reinforcement Learning with Shared Semantic Spaces and Read to Play (R2-Play): Decision Transformer with Multimodal Game Instruction. Google‚Äôs earlier Multi-game Decision Transformers were based on DT, but it's also possible to explore MLLM-based approaches. Despite over a year passing, there hasn't been significant progress, which feels somewhat disappointing. |
| Can Transformers Reason Logically? A Study in SAT Solving | An interesting small experiment using SAT to demonstrate that LLM+CoT can indeed generalize to OOD cases within the same task. However, it does not prove how task-level OOD generalization would perform. The mechanical interpretability is not very solid. A key takeaway is that the form and length of SFT matter significantly. Other aspects of the paper are optional for review. |
| DA-Code: Agent Data Science Code Generation Benchmark for Large Language Models | This benchmark focuses on agent data science. Table 1 contains benchmarks that are worth considering for merging into a specialized area of code evaluation. Recommended for further reading. |
| MoE++: Accelerating Mixture-of-Experts Methods with Zero-Computation Experts | The paper introduces zero-experts and copy-experts, but these do not qualify as heterogeneous MoE since the sizes appear to be the same. The evaluation is incomplete. |
| The Moral Turing Test: Evaluating Human-LLM Alignment in Moral Decision-Making | Produced by GDM, this paper proposes a benchmark for moral dilemmas. |
| A Survey: Collaborative Hardware and Software Design in the Era of Large Language Models | A survey on hardware-based model architecture design. The content was briefly scanned and seems decent. |
| Agent S: An Open Agentic Framework that Uses Computers Like a Human | A GUI Agent framework that, upon brief inspection, does not offer particularly novel ideas. |
| Executing Arithmetic: Fine-Tuning Large Language Models as Turing Machines | A highly intriguing paper that proposes a Turing machine simulation with seven types of arithmetic operations. The design is interesting, and the paradigm could be valuable if expanded. It demonstrates high accuracy, and if the operations and memory could be further extended, it represents a potential inference-time scaling approach. Strongly recommended for reading and exploring extensions of this direction. |
| The Cognitive Capabilities of Generative AI: A Comparative Analysis with Human Benchmarks | A potentially valuable OOD benchmark similar to IQ tests.|
| COMMA: A Communicative Multimodal Multi-Agent Benchmark | A benchmark that evaluates multimodal multi-agent frameworks through interaction. This is a highly promising research direction, although it may lose novelty over time if over-published, becoming just a collection of strange puzzles. |
| WALL-E: World Alignment by Rule Learning Improves World Model-based LLM Agents | This work is similar to frameworks based on eight proposals, but the rule format feels trivial, and the action space limitations are insufficient. Overall, it is a mediocre agent-based project set in Minecraft. |
| LatteCLIP: Unsupervised CLIP Fine-Tuning via LMM-Synthetic Texts | A method for generating multimodal synthetic data based on MLLM. |
| From Exploration to Mastery: Enabling LLMs to Master Tools via Self-Driven Interactions | This paper highlights how the model‚Äôs understanding of tool documentation differs from that of humans. The approach refines the documentation to enhance the model‚Äôs understanding of tool usage. |
| MathCoder2: Better Math Reasoning from Continued Pretraining on Model-translated Mathematical Code | While the paper doesn‚Äôt provide much new information, the MathCodePile dataset is worth exploring for potential value and whether the pipeline is worth referencing. |
| DemoShapley: Valuation of Demonstrations for In-Context Learning | It is observed that high-value and low-value ICL samples significantly affect performance. |
| Evolutionary Contrastive Distillation for Language Model Alignment | It was noted that synthetic preferences, constructed with combinatorial instructions (with additional format requirements), are beneficial for the model‚Äôs learning. This might be due to such preference data directly optimizing the ability to connect previously unconnected internal patterns. It is worth following up and recommended for further reading. |
| MRAG-Bench: Vision-Centric Evaluation for Retrieval-Augmented Multimodal Models | A multimodal RAG benchmark. |
| Mars: Situated Inductive Reasoning in an Open-World Environment | An interactive environment designed to test the fluid intelligence of models independent of pre-trained knowledge. However, the maintenance could be challenging, so it may not be worth pursuing. It primarily focuses on agent-based frameworks. |
| A Closer Look at Machine Unlearning for Large Language Models | - |
| Packing Analysis: Packing Is More Appropriate for Large Models or Datasets in Supervised Fine-tuning | - |
| Unlearning-based Neural Interpretations | - |
| Reward-Augmented Data Enhances Direct Preference Alignment of LLMs | - |
| Efficiently Learning at Test-Time: Active Fine-Tuning of LLMs | - |
| Benchmarking Agentic Workflow Generation | The name is well-chosen, and the direction is promising. However, the data diversity and quality are lacking. Workflow-based evaluation is a highly valuable topic. For instance, Coze and Difny represent two excellent examples. If we consider LLMs as productivity tools, two key points arise: (1) Can LLMs design reasonable workflows for common workflows in various professions? (2) Can LLMs execute these workflows with proper reasoning? A model that meets both criteria would be a valuable productivity tool in such scenarios. However, this benchmark‚Äôs domain categorization is overly simplistic and limited to academic agent topics. |
| Do Current Language Models Support Code Intelligence for R Programming Language? | An R Code evaluation worth considering for potential merge value. |
| GameTraversalBenchmark: Evaluating Planning Abilities Of Large Language Models Through Traversing 2D Game Maps | A potential OOD benchmark. |
| Temporal-Difference Variational Continual Learning | - |
| Learning Tree Pattern Transformations | - |
| AgentBank: Towards Generalized LLM Agents via Fine-Tuning on 50000+ Interaction Trajectories | A large-scale agent instruct dataset with CoT that has the potential for reformalizing the deep search reliability of models. The dataset‚Äôs reliability needs to be double-checked.|
| Automatic Curriculum Expert Iteration for Reliable LLM Reasoning | - |
| Detecting Training Data of Large Language Models via Expectation Maximization | - |
| MKGL: Mastery of a Three-Word Language | Worth reading. The takeaway is that LLMs can generalize reasoning trajectories on KGs by utilizing KG-based vocabulary. |
| Upcycling Large Language Models into Mixture of Experts | - |
| Jump Your Steps: Optimizing Sampling Schedule of Discrete Diffusion Models | - |

</table>

</details>

<hr/>

If you are intereted in the work published by us, please navigate to our [full paper list](https://huggingface.co/collections/m-a-p/m-a-p-full-paper-list-65e070a694c7b01c5547fbff).
