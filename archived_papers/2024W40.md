<h1 align="center"><img src="https://cdn-avatars.huggingface.co/v1/production/uploads/63839e9962badff4326cf360/k4Q7R4XLDMp_1VF4C6GEd.jpeg" width="25"> M-A-P Daily Paper</h1>
<p align="center">
<a href="https://github.com/DenverCoder1/readme-typing-svg"><img src="https://media.giphy.com/media/Rn26lWjqA0uUU/giphy.gif" width="100"></a>
</p>
<hr/>
<h4 align="center">The <a href=https://m-a-p.ai>M-A-P</a> daily paper project curates and reviews a selection of new papers published daily on arXiv, providing insightful commentary on cutting-edge research across various scientific disciplines.</h4>
<br>
<hr/>

[back to main page](https://m-a-p.ai/DailyPaper)


## üõ†Ô∏è Papers This Week 

(Expand to View)

<details>
<summary> <b>28/9/2024</b> </summary>

<table class="center">

| Paper | Comments |
|:-------------|:-------------|
| MIO: A Foundation Model on Multimodal Tokens | Promotes the paper the contributor is involved in, focusing on joint modeling of multimodal tokens. While the paradigm itself is not particularly unique, the summarization and organization of the pretraining and supervised fine-tuning (SFT) data are among the most solid in currently available Any2Any models. This is an initial version, and more ablation studies will be released by the first author. Another concurrent project is recommended: OmniBench: Towards The Future of Universal Omni-Language Models, which explores an imaginative research direction. |
| Emu3: Next-Token Prediction is All You Need | BAAI‚Äôs Any2Any model with several notable points in data processing: (1) Optical flaw removal in frame transitions with minimal/extreme motion. (2) Supplementary data specific to image understanding was added during pretraining. (3) Introduced [SOV], [SOT], and [EOV] tokens for parsing, meta-text, and vision tokens. The training process incorporates DPO. |
| Infer Human's Intentions Before Following Natural Language Instructions | A very simple intuition and method. The core takeaway is that instructions may contain ambiguity, leading to discrepancies between the intended meaning and the instructions themselves. The idea is to analyze what humans actually want robots to do in a specific context, integrate that into the instructions, and then have the robot execute them accordingly. |
| Compositional Hardness of Code in Large Language Models -- A Probabilistic Perspective | Recommended reading. The assumption seems not very strong, and it provides a probabilistic explanation of why decomposing a problem into multiple sub-problems is beneficial. The proof has not been thoroughly examined yet, so it could be worth looking at more carefully to check for any issues. |
| StressPrompt: Does Stress Impact Large Language Models and Human Performance Similarly? | The takeaway is that, similar to humans, models work more efficiently under moderate stress (following the Yerkes-Dodson law). This type of research could be considered "model behavioral psychology," as there have been many interesting findings recently in this area, though the credibility of such conclusions is about 50-50. |
| Enhancing Elusive Clues in Knowledge Learning by Contrasting Attention of Language Models | An interesting mechanism. By comparing the attention distribution of small and large models when reading the same knowledge-intensive documents, certain tokens are dropped to encourage models to learn non-obvious but important clues, improving performance. Notably, large models also show improvements, suggesting that learning irrelevant information still affects larger models. However, the experiments are not particularly convincing. |
| Explanation Bottleneck Models | A preliminary concept for a VAE-based explanation model, dubbed Concept Set Free. |
| FactorSim: Generative Simulation via Factorized Representation | Recommended reading. This seems to emulate human spatial imagination and environmental reasoning abilities, complementing reinforcement learning approaches. It‚Äôs worth mentioning another paper from two years ago, co-authored by GDM: Mind's Eye: Grounded Language Model Reasoning through Simulation. Simulated environments, outside of code/math scenarios, have significant exploratory potential. These environments present low-hanging fruits in interactive chain-of-thought (CoT) scenarios. For example, one could create a simulated chemistry lab where the model decides what actions to perform and summarizes the lab‚Äôs feedback. Alternatively, with games like Atari, the model could quickly learn after reading a tutorial, and generalize some skills. This seems like a promising research area. |
| Just Say What You Want: Only-Prompting Self-Rewarding Online Preference Optimization | - |
| Human Mobility Modeling with Limited Information via Large Language Models | This paper seems of limited use. However, the datasets V and A&B related to human behavior monitoring appear interesting. It raises the possibility of collecting daily behavior patterns across various professions in a similar manner. Noteworthy datasets include the National Household Travel Survey Dataset and the Activity-Based Model Dataset from the Southern California Association of Governments. |
| MaskLLM: Learnable Semi-Structured Sparsity for Large Language Models | Recommended reading. This paper introduces a learnable mask to achieve domain adaptation. There is an important underlying insight here: the rare downstream patterns learned during pretraining may have been mastered, but the alignment might still be off. The method is novel. |
| Exploring Semantic Clustering in Deep Reinforcement Learning for Video Games | This study investigates what kinds of video games are most similar to each other. |
| Post-hoc Reward Calibration: A Case Study on Length Bias | Recommended reading. A very intuitive way to edit rewards post hoc, first estimating the bias and then removing it from the reward. The approach feels very adaptable. |
| Search for Efficient Large Language Models | - |
| FreeEdit: Mask-free Reference-based Image Editing with Multi-modal Instruction | - |
| HydraViT: Stacking Heads for a Scalable ViT | - |
| Why Companies "Democratize" Artificial Intelligence: The Case of Open Source Software Donations | A systematic analysis of the benefits of companies funding open-source projects. The conclusion is that there are numerous advantages‚Äîcost-saving, gaining attention, and boosting engagement. More open-source initiatives are encouraged. |
| Inference-Time Language Model Alignment via Integrated Value Guidance | Aligns or enhances alignment during inference. If instruction-following is a mechanical pattern for LLMs, there is a training-free possibility of achieving alignment through controlling attention pattern composition. A related Stanford project was noted recently. |
| Language Models as Zero-shot Lossless Gradient Compressors: Towards General Neural Parameter Prior Models | Recommended reading. The claim is that LLMs as priors for gradient setting achieve state-of-the-art results. |
| Self-supervised Preference Optimization: Enhance Your Language Model with Preference Degree Awareness | Recommended reading. The intuition feels simple and effective, with the method being less important. Human preferences have degrees and shouldn‚Äôt be modeled as binary. |
| What Would You Ask When You First Saw a2+b2=c2? Evaluating LLM on Curiosity-Driven Questioning | Explores an interesting question: how well do LLMs actively seek to fill in knowledge gaps as a prerequisite for understanding? |
| HDFlow: Enhancing LLM Complex Problem-Solving with Hybrid Thinking and Dynamic Workflows | - |
| CSCE: Boosting LLM Reasoning by Simultaneous Enhancing of Casual Significance and Consistency | Highly recommended reading. The paper highlights an understanding the author strongly agrees with: after each inference step in solving a problem, one should evaluate whether the step contributes to solving the problem meaningfully. Sometimes, context can act as noise. Instead of optimizing a chain, it's more appropriate to optimize the dependencies‚Äîwhat should be solved first and whether solving a sub-problem contributes to the main problem. However, the methodology is somewhat rough. |
</table>

</details>


<details>
<summary> <b>26/9/2024</b> </summary>

| Paper | Comments |
|:-------------|:-------------|
| Beyond Following: Mixing Active Initiative into Computational Creativity | This is an HCI study on user-AI collaborative creativity. There were many similar studies one or two years ago. It seems that apart from instruction following, this represents a creative pattern that remains to be explored. |
| HyperAgent: Generalist Software Engineering Agents to Solve Coding Tasks at Scale | A Multi-Agent SE framework, introducing Feature Localization and Edition, which are distinct from previous frameworks. It seems more aligned with an agile development workflow. |
| Task-oriented Prompt Enhancement via Script Generation | SoT+PoT. The most obvious value of such XoT approaches, especially after o1, is how to extract a large set of scalable high-confidence data for training the model. |
| VPTQ: Extreme Low-bit Vector Post-Training Quantization for Large Language Models | - |
| Harnessing Diversity for Important Data Selection in Pretraining Large Language Models | A framework for estimating pretraining data quality based on clustering and downstream performance. From a pretraining perspective, this approach doesn't seem particularly useful. However, it might be valuable for extracting data sources for producing SFT by leveraging the clustering method. |
| Algorithmic Drift: A Simulation Framework to Study the Effects of Recommender Systems on User Preferences | - |
| GSplatLoc: Grounding Keypoint Descriptors into 3D Gaussian Splatting for Improved Visual Localization | - |
| Demystifying Issues, Causes and Solutions in LLM Open-Source Projects | An interesting read. It analyzes issues in LLM open-source projects. |
| Vision-Language Model Fine-Tuning via Simple Parameter-Efficient Modification | Figure 5 demonstrates the actual impact on distribution. There are many unnatural aspects within CLIP, for example, humans decide what to focus on based on their own context, which is evident in several benchmarks. The bottleneck in MLLM's visual information during image encoder pretraining is quite severe, and there is significant room for improvement. |
| Uncertainty Representations in State-Space Layers for Deep Reinforcement Learning under Partial Observability | - |
| Enhancing Temporal Sensitivity and Reasoning for Time-Sensitive Question Answering | The methods used here are questionable and can be ignored. However, the four TSQA benchmarks used might be valuable as corner cases that LLM users could experience. |
| Towards User-Focused Research in Training Data Attribution for Human-Centered Explainable AI | - |
| Counterfactual Token Generation in Large Language Models | - |
| INT-FlashAttention: Enabling Flash Attention for INT8 Quantization | Baichuan's INT8 + Flash Attention approach. |
| How to Connect Speech Foundation Models and Large Language Models? What Matters and What Does Not | - |
| Programming Every Example: Lifting Pre-training Data Quality like Experts at Scale | LLM-based data pretrain filtering, with a related training dataset released. This is indeed the direction for the future and is recommended reading. |
| FineZip : Pushing the Limits of Large Language Models for Practical Lossless Text Compression | - |
| AXCEL: Automated eXplainable Consistency Evaluation using LLMs | - |
| Turn Every Application into an Agent: Towards Efficient Human-Agent-Computer Interaction with API-First LLM-Based Agents | Shorter CoT combined with tool-using calls can produce many useful agents, rather than relying on excessively long CoTs (especially considering potential redundancy). Recommended reading. An interesting piece of agent work. Creating new APIs is akin to creating reasoning shortcuts, similar to encapsulating functions in code. |
| Tell Me What You Don't Know: Enhancing Refusal Capabilities of Role-Playing Agents via Representation Space Analysis and Editing | - |
| Multi-objective Evolution of Heuristic Using Large Language Model | - |
| Attention Prompting on Image for Large Vision-Language Models | Recommended reading. It employs an embarrassingly naive yet effective trick. When humans look at images, they decide what to focus on based on context. For MLLMs, adjusting the CLIP embedding at inference-time based on context is a highly meaningful research topic. |
| A Survey of Low-bit Large Language Models: Basics, Systems, and Algorithms | - |
| Dynamic-Width Speculative Beam Decoding for Efficient LLM Inference | - |
| Unsupervised Text Representation Learning via Instruction-Tuning for Zero-Shot Dense Retrieval | - |

</details>

<details>
<summary> <b>25/9/2024</b> </summary>
  
| Paper | Comments |
|:-------------|:-------------|
| HelloBench: Evaluating Long Text Generation Capabilities of Large Language Models | Developed with interns, currently the best open-source long-text generation benchmark on the market. The sections on Open-Ended QA and Heuristic Text Generation are particularly valuable. |
| MonoFormer: One Transformer for Both Diffusion and Autoregression | A surprisingly simplistic approach combining Diffusion and Autoregressive techniques. |
| EuroLLM: Multilingual Language Models for Europe | Highly recommended! The Joint Scaling Law is intriguing and may be extrapolated to domain-specific ratios. Once the number of domains increases, it could yield a higher ROI than the D-CPT Law or similar optimization functions. |
| MaskBit: Embedding-free Image Generation via Bit Tokens | - |
| CJEval: A Benchmark for Assessing Large Language Models Using Chinese Junior High School Exam Data | Recommended for reading. It's a high-quality benchmark. Notably, they mention that Tencent annotated over 20,000 CoT questions, but it is unclear how much that cost. It might have been better used for training on o1 tasks. |
| LLM Echo Chamber: Personalized and Automated Disinformation | - |
| On the Complexity of Neural Computation in Superposition | - |
| Watch Your Steps: Observable and Modular Chains of Thought | This is CMU's version of DoT. It feels similar to a recent THU paper, but this one is written more clearly and is easier to understand. There are some differences in the mechanism, but the approach of identifying and naming steps, defining the input/output behavior, and replacing CoT explanations with formalized steps for the same examples is explained more comprehensibly here. |
| Reward-Robust RLHF in LLMs | - |
| Smirk: An Atomically Complete Tokenizer for Molecular Foundation Models | - |
| ControlMath: Controllable Data Generation Promotes Math Generalist Models | By retaining only the more difficult problems during each round of synthetic data iteration, the difficulty of the math problems generated by the model is improved. |
| Parse Trees Guided LLM Prompt Compression | - |
| Tag Map: A Text-Based Map for Spatial Reasoning and Navigation with Large Language Models | No comment provided. |
| In-Context Learning May Not Elicit Trustworthy Reasoning: A-Not-B Errors in Pretrained Language Models | Raises a valuable issue: LLMs are not sensitive to trivial context changes, leading to the A-Not-B problem. |
| VLMine: Long-Tail Data Mining with Vision Language Models | - |
| TFG: Unified Training-Free Guidance for Diffusion Models | - |
| Empirical Insights on Fine-Tuning Large Language Models for Question-Answering | Finding 1 and Figure 4 are interesting. |
| Adaptive Learn-then-Test: Statistically Valid and Efficient Hyperparameter Selection | An interesting read, with a compelling automated hyperparameter search mechanism. |
| Fine-Tuning is Fine, if Calibrated | - |
| Steward: Natural Language Web Automation | - |
| CLSP: High-Fidelity Contrastive Language-State Pre-training for Agent State Representation | - |

</details>

<details>
<summary> <b>24/9/2024</b> </summary>

| Paper | Comments |
|:-------------|:-------------|
| OmniBench: Towards The Future of Universal Omni-Language Models | The authors put significant effort into data annotation for this paper. In OmniBench, each data sample requires simultaneous use of audio, image, and textual information to answer during inference. Every sample was manually checked by coauthors, and missing one modality reduces the accuracy to guessing from 2-3 options. There are two key takeaways: 1) Currently, none of the open-source Omni models can process all three modalities simultaneously, and even closed-source models have limited capabilities with no cross-modal generalization. 2) The performance of Multimodal Large Language Models (MLLMs) is constrained under image description, audio transcription, and text response conditions, with models like Gemini reaching this upper bound and Reka-core trailing by about 10 points. However, the encoders still lose a considerable amount of information. It is rumored that GDM has a similar system, which could become a future benchmark for Omni-Language Models (OLM). |
| Can-Do! A Dataset and Neuro-Symbolic Grounded Framework for Embodied Planning with Large Multimodal Models | A potentially useful embodied multimodal benchmark. |
| LLMs are One-Shot URL Classifiers and Explainers | The same discovery was made about six months ago. Our experiments were slightly more extreme, showing that GPT-3.5 and Claude are excellent URL classifiers, capable of determining the source based on the root domain. This is significant because this ability can be leveraged to gather seed data for various domains, enabling the cold-start training of models like fastText and BERT. This can further assist in classifying already pre-collected training data. We plan to release a dataset with 67 domain-specific categories within 2-3 weeks. |
| A-VL: Adaptive Attention for Large Vision-Language Models | In MLLMs, images and text have distinct self-attention patterns. Therefore, different caching modes are designed for each modality during inference. The visual component ‚Äústores the cache of potentially useful information but only computes the most critical parts,‚Äù while the language part prioritizes local information. |
| VLEU: a Method for Automatic Evaluation for Generalizability of Text-to-Image Models | A benchmark for evaluating the generalization of text-to-image models. |
| Distribution-Level Feature Distancing for Machine Unlearning: Towards a Better Trade-off Between Model Utility and Forgetting | Introduces Optimal Transport to prevent the model from being misled by forgetting. While the author does not frequently read such papers, this approach appears to make sense. |
| Target-Aware Language Modeling via Granular Data Sampling | Introduces n-gram feature recognition related to downstream tasks to identify relevant data, aiming to enhance downstream task performance without sacrificing the performance of other tasks. |
| Past Meets Present: Creating Historical Analogy with Large Language Models | - |
| Do Large Language Models have Problem-Solving Capability under Incomplete Information Scenarios? | A good design concept for an interactive benchmark, though the data quality and differentiation seem to be lacking, and the hard mode is not particularly challenging. Examples include "Who is Undercover" and "Twenty Questions". |
| VLM's Eye Examination: Instruct and Inspect Visual Competency of Vision Language Models | 1) VLMs exhibit varying sensitivity to different colors but consistently show insensitivity to green across various VLMs. 2) They demonstrate differing shape sensitivity and semantic recognition based on the LLM‚Äôs capacity, despite using the same fixed visual encoder. |
| Identify As A Human Does: A Pathfinder of Next-Generation Anti-Cheat Framework for First-Person Shooter Games | A framework for anti-cheat mechanisms in games. |
| Orthogonal Finetuning for Direct Preference Optimization | -  |
| Inference-Friendly Models With MixAttention | - |
| Scaling Laws of Decoder-Only Models on the Multilingual Machine Translation Task | No comment provided. |
| Efficiently Dispatching Flash Attention For Partially Filled Attention Masks | No comment provided. |
| Style over Substance: Failure Modes of LLM Judges in Alignment Benchmarking | Analyzes judgment biases in LLM-based benchmarking. |
| A Preliminary Study of o1 in Medicine: Are We Closer to an AI Doctor? | A brief review of AI applications in medicine, with little improvement noted. |
| VisScience: An Extensive Benchmark for Evaluating K12 Educational Multi-modal Scientific Reasoning | A benchmark similar to MMMU, potentially useful. |
| Drift to Remember | - |
| You Only Use Reactive Attention Slice For Long Context Retrieval | A Reactive Attention mechanism applied to retrieval-augmented generation (RAG). This work by Meta seems intuitively reasonable and is recommended for further reading. |
| Prompt Baking | A lightweight method for model parameter personalization based on prompts. This is an interesting small trick, recommended for further reading. |
| RNR: Teaching Large Language Models to Follow Roles and Rules | A potentially useful benchmark for role-playing scenarios. |
| Language agents achieve superhuman synthesis of scientific knowledge | - |
| MathGLM-Vision: Solving Mathematical Problems with Multi-Modal Large Language Model | - |
| A Multi-LLM Debiasing Framework | - |
| One-shot World Models Using a Transformer Trained on a Synthetic Prior | - |
| ChemEval: A Comprehensive Multi-Level Chemical Evaluation for Large Language Models | A useful domain-specific benchmark. |
| A is for Absorption: Studying Feature Splitting and Absorption in Sparse Autoencoders | Recommended reading. Describes a phenomenon called feature absorption in sparse autoencoders, which may affect the reliability of SAE. |
| Proof Automation with Large Language Models | Recommended reading. It decouples low-level proof from high-level speculative decoding in formal proof systems. |
| TracrBench: Generating Interpretability Testbeds with Large Language Models | A high-quality benchmark. |

</details>

<hr/>

If you are intereted in the work published by us, please navigate to our [full paper list](https://huggingface.co/collections/m-a-p/m-a-p-full-paper-list-65e070a694c7b01c5547fbff).
