<h1 align="center"><img src="https://cdn-avatars.huggingface.co/v1/production/uploads/63839e9962badff4326cf360/k4Q7R4XLDMp_1VF4C6GEd.jpeg" width="25"> M-A-P Daily Paper</h1>
<p align="center">
<a href="https://github.com/DenverCoder1/readme-typing-svg"><img src="https://media.giphy.com/media/Rn26lWjqA0uUU/giphy.gif" width="100"></a>
</p>
<hr/>
<h4 align="center">The <a href=https://m-a-p.ai>M-A-P</a> daily paper project curates and reviews a selection of new papers published daily on arXiv, providing insightful commentary on cutting-edge research across various scientific disciplines.</h4>
<br>
<hr/>

[back to main page](https://m-a-p.ai/DailyPaper)


## üõ†Ô∏è Papers This Week 

(Expand to View)

<details>
<summary> <b>20/9/2024</b> </summary>

<table class="center">
  
| Paper | Comments |
|:-------------|:-------------|
| Can VLMs Play Action Role-Playing Games? Take Black Myth Wukong as a Study Case | Conclusion 1: VL-Agents powered by 4o and Gemini outperform humans in playing Black Myth Wukong. Conclusion 2: 4o performs significantly better than Gemini in learning this type of planning. The collected dataset of Black Myth Wukong may prove quite useful. |
| KnowFormer: Revisiting Transformers for Knowledge Graph Reasoning | A cognitive model with relatively weak experiments. It uses a representation layer to denote the subsymbolic global workspace and an index layer to manage scheduling (containing symbols for concepts, time instances, and predicates). |
| How the (Tensor-) Brain uses Embeddings and Embodiment to Encode Senses and Decode Symbols | A cognitive model, but the experiments are relatively weak. It utilizes a representation layer to depict the subsymbolic global workspace and an index layer for managing and scheduling symbols (for concepts, time instances, and predicates). |
| Autoformalization of Game Descriptions using Large Language Models | An automated tool for converting text-based games into decision problems. It seems quite interesting and has the potential to be further explored and developed into a Dynamic Agentic Benchmark. |
| RAG-Modulo: Solving Sequential Tasks using Experience, Critics, and Language Models | Uses RAG to aid LLM-based agents in decision-making within interactive environments. Experiments conducted on BabyAI and AlfWorld. If replicable, it could be quite impressive. |
| MMSearch: Benchmarking the Potential of Large Models as Multi-modal Search Engines | A benchmark combining multimodality and search scenarios, seems more closely aligned with user needs than previous multimodal benchmarks. |
| Interpolating Video-LLMs: Toward Longer-sequence LMMs in a Training-free Manner | - |
| JourneyBench: A Challenging One-Stop Vision-Language Understanding Benchmark of Generated Images | - |
| Re-Introducing LayerNorm: Geometric Meaning, Irreversibility and a Comparative Study with RMSNorm | Recommended reading. TLDR: Subtracting the mean of a vector‚Äôs components equates to removing the vector's projection along the uniform vector. Layer normalization can be defined as the normalization of the vector‚Äôs component orthogonal to the uniform vector, with a scaling factor. Information lost during layer normalization cannot be recovered in the scale-and-shift step, making the process irreversible. |
| Scaling Smart: Accelerating Large Language Model Pre-training with Small Model Initialization | - |
| Assessing the Zero-Shot Capabilities of LLMs for Action Evaluation in RL | Utilizes LLMs for RL value functions; LLM for RL. Recommends referencing the prior work of Xidong Feng in this domain: "Uncertainty of Thoughts: Uncertainty-Aware Planning Enhances Information Seeking in Large Language Models," "Contextual Transformer for Offline Meta Reinforcement Learning," and "Natural Language Reinforcement Learning." |
| MEXMA: Token-level objectives improve sentence representations | Sentence encoders also require token-level objectives. |
| Iteration of Thought: Leveraging Inner Dialogue for Autonomous Large Language Model Reasoning | Another Iteration of Thought (XoT). Introduces iterative reasoning. |
| PersonaFlow: Boosting Research Ideation with LLM-Simulated Expert Personas | Can be processed into a more complex version of the cosmopedia/persona synthetic data pipeline. |
| Scaling FP8 training to trillion-token LLMs | - |
| Prompts Are Programs Too! Understanding How Developers Build Software Containing Prompts | - |
| Neural Networks Generalize on Low Complexity Data | - |
| Mixture of Diverse Size Experts | - |

</table>

</details>


<details>
<summary> <b>19/9/2024</b> </summary>
<table class="center">

  | Paper | Comments |
|:-------------|:-------------|
| AIvril: AI-Driven RTL Generation With Verification In-The-Loop | RTLRewriter: Methodologies for Large Models aided RTL Code Optimization: Similar to the previous paper, this work involves the use of large language models (LLMs) for RTL design. There seems to be significant performance improvements compared to earlier in the year, although the specifics are somewhat unclear. |
| Self-Contrastive Forward-Forward Algorithm | Finding the Subjective Truth: Collecting 2 Million Votes for Comprehensive Gen-AI Model Evaluation: A useful dataset for image generation preference. It is recommended to explore our related work, VideoScore: Building Automatic Metrics to Simulate Fine-grained Human Feedback for Video Generation, as model-based AIGC metrics seem to be a promising direction, especially for music and video. Similar work in image generation is already available. |
| Improving LLM Reasoning with Multi-Agent Tree-of-Thought Validator Agent | This paper attaches a validation mechanism to each thought branch in the Tree-of-Thought (ToT) framework. |
| Qwen2-VL: Enhancing Vision-Language Model's Perception of the World at Any Resolution | This paper employs expected techniques. Intuitively, native support for dynamic resolution does not seem to make much sense for semantic image-text mapping, as seen in models like CLIP. (Pure personal speculation: if a similar region of the image is being described, does a higher resolution imply that the image will require more tokens? This seems unrelated to the implicit semantics within the image.) Techniques like M-RoPE have been widely discussed in prior literature. |
| Qwen2.5-Math Technical Report: Toward Mathematical Expert Model via Self-Improvement | Better data and annotations are all that‚Äôs needed for improvement! |
| Preference Tuning with Human Feedback on Language, Speech, and Vision Tasks: A Survey | - |
| Mamba Fusion: Learning Actions Through Questioning | - |
| GRIN: GRadient-INformed MoE | Figure 6 is quite interesting. GRIN demonstrates domain-level expert clustering, though the model is 16 experts choosing 2, rather than a finer-grained expert configuration. It‚Äôs unclear whether this would make a difference. Previously, Meta‚Äôs BTX revealed an interesting phenomenon where well-separated domain experts become more similar after joint training. From a dense model perspective, expert divergence is relatively natural. Recommended reading: Branch-Train-MiX: Mixing Expert LLMs into a Mixture-of-Experts LLM. |
| Computational Dynamical Systems | - |
| To CoT or not to CoT? Chain-of-thought helps mainly on math and symbolic reasoning | Recommended reading: This paper compares the benefits of Chain-of-Thought (CoT) across various downstream tasks, confirming that CoT primarily benefits symbolic execution. |

</table>
</details>

<details>
<summary> <b>16-18/9/2024</b> </summary>
<table class="center">

| Paper | Comments |
|:-------------|:-------------|
| United in Diversity? Contextual Biases in LLM-Based Predictions of the 2024 European Parliament Elections | This study investigates the political biases hidden within LLMs using data from the Brexit referendum. It verifies a consensus that LLMs are not suitable for direct application in certain computational social science research scenarios. The prompts used do not elicit the political views and voting tendencies of diverse background groups, and a detailed analysis of how biases are embedded within the model parameters is lacking. |
| Evaluating the Performance of Large Language Models in Competitive Programming: A Multi-Year, Multi-Grade Analysis | This research tests the coding capabilities of LLMs using data from the Romanian Informatics Olympiad, which may serve as a suitable and directly mergeable test set. It finds that GPT outperforms other models significantly, though no Hugging Face link is provided. |
| Inf-MLLM: Efficient Streaming Inference of Multimodal Large Language Models on a Single GPU | The analysis of four attention patterns in MLLMs is intriguing: Pattern 1 indicates that recent tokens receive high attention scores; Pattern 2 shows that tokens derived from videos typically have elevated attention scores; Pattern 3 reveals that positions with high attention scores manifest as vertical lines; and Pattern 4 suggests that high attention scores advance as multi-round inference progresses. Based on these defined attention patterns, the study further introduces attention bias to eliminate irrelevant key-value caches. |
| Cross-Entropy Optimization for Hyperparameter Optimization in Stochastic Gradient-based Approaches to Train Deep Neural Networks | - |
| Robust Training of Neural Networks at Arbitrary Precision and Sparsity | - |
| Unleash LLMs Potential for Recommendation by Coordinating Twin-Tower Dynamic Semantic Token Generator | This work introduces instructions and user representations into a single-tower generative recommendation system. |
| What Is Wrong with My Model? Identifying Systematic Problems with Semantic Data Slicing | This is a toy demonstration based on the LLM Data Slicing Hypothesis standards and verification. |
| Language Models "Grok" to Copy | This paper presents three arguments that suggest: 1. The ability to copy is a form of grokking during training; 2. The ability to copy is independent of the total number of tokens in training; and 3. Induction heads deepen from shallower to deeper layers, potentially indicating that the ability to copy evolves into a higher-order intrinsic capability, related to what is learned in deeper layers. |
| Symbolic Regression with a Learned Concept Library | This work introduces a toy concept dataset that may be suitable for LLM Physics research, referred to as LaSR. |
| Planning Transformer: Long-Horizon Offline Reinforcement Learning with Planning Tokens | This paper discusses Planning and Pausing Tokens in the Decision Transformer. |
| TG-LLaVA: Text Guided LLaVA via Learnable Latent Embeddings | This study enables the vision encoder to obtain more text context-related information. |
| ValueCompass: A Framework of Fundamental Values for Human-AI Alignment | - |
| MindScape Study: Integrating LLM and Behavioral Sensing for Personalized AI-Driven Journaling Experiences |  |
| Explore the Hallucination on Low-level Perception for MLLMs | This is an interesting test for multimodal models, assessing their ability to recognize relative positioning of entities in visual inputs. The findings indicate that the models perform poorly, highlighting a significant challenge for MLLMs. This benchmark is meaningful and can be improved by enhancing the data used. |
| Towards Data Contamination Detection for Modern Large Language Models: Limitations, Inconsistencies, and Oracle Challenges | This research proposes a Local Order Quiz approach for contamination detection, revealing that contamination in GPT-4 is quite substantial, particularly within the training datasets of HumanEval and GSM8k. |
| SelECT-SQL: Self-correcting ensemble Chain-of-Thought for Text-to-SQL | - |
| On the Diagram of Thought | This work models reasoning as a directed acyclic graph and introduces role-specific tokens. |
| Can GPT-O1 Kill All Bugs? An Evaluation of GPT-Family LLMs on QuixBugs | This is a preliminary evaluation report for O1 Debug. |
| Towards Explainable Automated Data Quality Enhancement without Domain Knowledge | - |
| An Efficient Self-Learning Framework For Interactive Spoken Dialog Systems | - |
| Large Language Model Based Generative Error Correction: A Challenge and Baselines for Speech Recognition, Speaker Tagging, and Emotion Recognition | - |
| Towards Data-Centric RLHF: Simple Metrics for Preference Dataset Comparison | This study analyzes the quality of preference datasets without requiring training, introducing three metrics based on scale, label noise, and information content. While the approach is rudimentary, it offers valuable insights. |
| Audio Transformers: Transformer Architectures For Large Scale Audio Understanding. Adieu Convolutions | - |
| Self-Attention Limits Working Memory Capacity of Transformer-Based Models | This research verifies the use of a specific attention paradigm to address problems using the N-back dataset. It represents a study in LLM physics, which faces limitations due to reliance on toy data, making it difficult to generalize conclusions to real LLM pretraining scenarios. |
| Less is More: A Simple yet Effective Token Reduction Method for Efficient Multi-modal LLMs | - |
| Fast Analysis of the OpenAI O1-Preview Model in Solving Random K-SAT Problem: Does the LLM Solve the Problem Itself or Call an External SAT Solver? | This is another preliminary evaluation report for O1 SAT solving capabilities. |
| Learning Source Disentanglement in Neural Audio Codec | - |
| LOLA -- An Open-Source Massively Multilingual Large Language Model | - |
| OmniGen: Unified Image Generation | - |
| NVLM: Open Frontier-Class Multimodal LLMs | - |
| Apollo: Band-sequence Modeling for High-Quality Audio Restoration | - |
| When Context Leads but Parametric Memory Follows in Large Language Models | This paper provides an intriguing evaluation and analysis of how models utilize embedded knowledge from internal parameters and information from context. It highlights a consistent pattern of reliance on both contextual (approximately 70%) and parametric (approximately 30%) knowledge across models. The WikiAtomic dataset appears to resemble Hotpot QA, reintroducing wiki-based multi-hop reasoning synthetic data. |
| Scores as Actions: a framework of fine-tuning diffusion models by continuous-time reinforcement learning | - |
| AI-LieDar: Examine the Trade-off Between Utility and Truthfulness in LLM Agents | - |
| CPL: Critical Planning Step Learning Boosts LLM Generalization in Reasoning Tasks | This work utilizes MCTS for planning instead of relying on single-step actions. |
| Explaining Datasets in Words: Statistical Models with Natural Language Parameters | - |
| NEST-RQ: Next Token Prediction for Speech Self-Supervised Pre-Training | - |
| Text-To-Speech Synthesis In The Wild | This study presents a large-scale synthetic TTS dataset. |
| jina-embeddings-v3: Multilingual Embeddings With Task LoRA | - |
| Kolmogorov-Arnold Transformer | The reviewer expresses skepticism regarding the KAN approach. |
| Seed-Music: A Unified Framework for High Quality and Controlled Music Generation | - |
| On the limits of agency in agent-based models | - |
| Autoregressive + Chain of Thought (CoT) ‚âÉ Recurrent: Recurrence's Role in Language Models and a Revisit of Recurrent Transformer | This pivotal paper theoretically demonstrates that CoT functions similarly to recurrence for the model. |
| Expediting and Elevating Large Language Model Reasoning via Hidden Chain-of-Thought Decoding | This work activates multi-step reasoning through Hidden Chain-of-Thought decoding. |

</table>
</details>
<hr/>

If you are intereted in the work published by us, please navigate to our [full paper list](https://huggingface.co/collections/m-a-p/m-a-p-full-paper-list-65e070a694c7b01c5547fbff).

